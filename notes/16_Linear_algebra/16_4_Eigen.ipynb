{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 16: Elements of linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C.4 Eigenvalues and Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explain general linear functions and their relationship to matrices.  We spend considerable time discussing the special case of the square matrix, for which we describe the important topics of eigenvectors and eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code cell won't be shown in the HTML version of this notebook\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "from mlrefined_libraries import linear_algebra_library as linlib\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear functions and rectangular matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using any $P\\times N$ matrix of values $\\mathbf{X}$ \n",
    "\n",
    "$$\n",
    "\\mathbf{X}= \\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\cdots & x_{1N}\\\\\n",
    "x_{21} & x_{22} & \\cdots & x_{2N}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "x_{P1} & x_{P2} & \\cdots & x_{PN}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "defines a linear function via right matrix-vector multiplication (discussed in the previous post) with a $N\\times 1$ vector of variables \n",
    "\n",
    "$$\n",
    "\\mathbf{w} =\n",
    "\\begin{bmatrix}\n",
    " w_1 \\\\\n",
    " w_2 \\\\\n",
    " \\vdots \\\\\n",
    " w_N\n",
    " \\end{bmatrix}\n",
    " $$\n",
    " \n",
    " as $\\mathbf{X}\\mathbf{w}$  Written more formally as \n",
    " \n",
    " $$\n",
    " g(\\mathbf{w}) = \\mathbf{X}\\mathbf{w}\n",
    " $$\n",
    " \n",
    " note that because $\\mathbf{X}$ and $\\mathbf{w}$ are of dimensions $P\\times N$ and $N\\times 1$ respectively, the output $g(\\mathbf{w})$ for any input $\\mathbf{w}$ is a $P\\times 1$ vector itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a function is difficult to visualize for even moderate values of $P$ and $N$, but we have already seen a number of instances of this function before (and will see more below).  $g$ is called a *linear* function because it directly generalizes the concept of a line or hyperplane.  To see this notice that when $P = 1$ the matrix is reduced to a single row, and the resulting function is reduced to one sum of the form\n",
    "\n",
    "$$\n",
    "g(\\mathbf{w}) = x_{11}w_1 + x_{12}w_2 + \\cdots x_{1N}w_N\n",
    "$$\n",
    "\n",
    "which is just a single hyperplane in $N-1$ dimensions.  In fact, from this perspective, we can think of the general case when $P > 1$ of $g(\\mathbf{w})$ consisting as the output of $P$ such hyperplanes evaluated simultaneously over the same input $\\mathbf{w}$.  \n",
    "\n",
    "$$\n",
    "g(\\mathbf{w}) =\n",
    "\\begin{bmatrix}\n",
    "x_{11}w_1 + x_{12}w_2 + \\cdots x_{1N}w_N \\\\\n",
    "x_{21}w_1 + x_{22}w_2 + \\cdots x_{2N}w_N \\\\\n",
    "\\vdots \\\\\n",
    "x_{P1}w_1 + x_{P2}w_2 + \\cdots x_{PN}w_N \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Linear functions and square matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When both dimensions of a matrix are equal, i.e., when $P=N$, the matrix $\\mathbf{X}$ is called a *square matrix*.  We can visually examine the affect of such a function when $N = 2$ by viewing the way two-dimensional points are shifted due to its transformation.  \n",
    "\n",
    "In the next Python cell we provide just such a visualization using a slider widget and the $2\\times 2$ matrix whose entries were decided on at random as\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "0.72603839, -1.05918159 \\\\\n",
    "-0.19991361, -0.94740542 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember what this means, for an input point $\\mathbf{w} = \\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}$ the corresponding output is also length two, and takes the form\n",
    "\n",
    "$$\n",
    "g(\\mathbf{w}) = \n",
    "\\begin{bmatrix}\n",
    "0.72603839w_0 -1.05918159w_1 \\\\\n",
    "-0.19991361w_0  -0.94740542w_1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the widget is initialized a coarse set of grid lines  drawn in the figure below.  The point of this visualization is to animate how each point constituting these grid lines - and thus the entire space itself - is transformed using the matrix above. \n",
    "\n",
    "As you move the slider to the right the transformation provided by $g(\\mathbf{w})$ is gradually shown, and is completed when the slider is pushed all the way to the right.  For visualization purposes a circle of radius 2 is drawn on top of the grid and is transformed along with it.  Try moving the slider back and forth to get a feel for how the space is warped by the function $g(\\mathbf{w}) = \\mathbf{X}\\mathbf{w}$ using the pre-chosen matrix.  If you pull the notebook associated with this post you can swap out the given matrix with any $2\\times 2$ matrix of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# define a random matrix and visualize its transformation\n",
    "mat1 = np.array([[ 0.72603839, -1.05918159],[-0.19991361, -0.94740542]])\n",
    "savepath = 'videos/animation_3.mp4'\n",
    "linlib.transform_animators.transform2d_animator(savepath=savepath,mat1 = mat1,num_frames = 100,fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1000\" height=\"400\" controls loop>\n",
       "  <source src=\"videos/animation_3.mp4\" type=\"video/mp4\">\n",
       "  </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# load video into notebook\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"1000\" height=\"400\" controls loop>\n",
    "  <source src=\"videos/animation_3.mp4\" type=\"video/mp4\">\n",
    "  </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square matrices and eigenvectors / eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous visualization is interesting in its own right, but if examined closely can also be used to provoke the notion of what are called *eigenvectors*.  These are the handful of directions that - unlike most others that are warped and twisted by multiplication with the given matrix - are only *scaled* by the function (that is only stretched / compressed and / or flipped).  \n",
    "\n",
    "In the next Python cell we again show the graduate transformation provided by the random matrix above.  This time - however - we also highlight these directions as black arrows.  Now once the slider is moved slightly to the right these two directions - called eigenvectors - will be highlighted on the plane.  As you move the slider all the way to the right notice how neither direction twists or warps - they are the only two directions so unaffected, as they are only scaled - by the multiplication of $\\mathbf{X}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# define a random matrix and visualize its transformation\n",
    "mat1 = np.array([[ 0.72603839, -1.05918159],[-0.19991361, -0.94740542]])\n",
    "savepath = 'videos/animation_4.mp4'\n",
    "linlib.transform_animators.transform2d_animator(savepath=savepath,mat1 = mat1,num_frames = 100,eigvecs_on = True,fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1000\" height=\"400\" controls loop>\n",
       "  <source src=\"videos/animation_4.mp4\" type=\"video/mp4\">\n",
       "  </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# load video into notebook\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"1000\" height=\"400\" controls loop>\n",
    "  <source src=\"videos/animation_4.mp4\" type=\"video/mp4\">\n",
    "  </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is a unique property of linear functions, most nonlinear functions do not treat any of their points so kindly.  Take for example this relatively simple looking nonlinear function\n",
    "\n",
    "$$\n",
    "g(\\mathbf{w}) = \n",
    "\\begin{bmatrix}\n",
    "w_0 + w_1\\\\\n",
    "w_0\\text{cos}(w_0 + w_1) \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If we use the same visualization as with the linear function above we we can see that this nonlinear function twists and turns every point in the plane - leaving no point merely a scaled version of itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# define a random matrix and visualize its transformation\n",
    "f = lambda w: np.asarray([w[0] + w[1], w[0]*np.cos(w[0] + w[1])])\n",
    "savepath = 'videos/animation_5.mp4'\n",
    "linlib.transform_animators.nonlinear_transform2d_animator(savepath=savepath,func = f,num_frames = 100,fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1000\" height=\"400\" controls loop>\n",
       "  <source src=\"videos/animation_5.mp4\" type=\"video/mp4\">\n",
       "  </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# load video into notebook\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"1000\" height=\"400\" controls loop>\n",
    "  <source src=\"videos/animation_5.mp4\" type=\"video/mp4\">\n",
    "  </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So indeed, linear functions based on an $2\\times 2$ square matrix are unique in that they affect *at most* two (linearly independent) directions by merely scaling them.  This holds more generally as well: a linear function based on an $N\\times N$ matrix affects at most $N$ linearly independent directions by simply scaling them.\n",
    "\n",
    "For an $N\\times N$ matrix $\\mathbf{X}$ each such direction $\\mathbf{v}$ (an $N\\times 1$ column vector) that is merely scaled by $\\mathbf{X}$ is called an *eigenvector*.  We formally write the fact that $\\mathbf{X}$ merely scales $\\mathbf{v}$ as\n",
    "\n",
    "$$\n",
    "\\mathbf{X}\\mathbf{v} = \\lambda \\mathbf{v}\n",
    "$$\n",
    "\n",
    "Here the value $\\lambda$ is precisely the amount by which $\\mathbf{X}$ scales $\\mathbf{v}$, and is called an *eigenvalue*.  In practice $\\lambda$ can take on real or complex values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The special case of the square symmetric matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The specific case of a linear function generated by a square symmetric matrix, that is an $N\\times N$ matrix $\\mathbf{X}$ where $\\mathbf{X} = \\mathbf{X}^T$, is an important special case of a square matrix that arises in a wide range of contexts (we will see such matrices arise as Hessians of a cost function associated with most fundamental supervised learning models).  For example, when $N = 2$ a symmetric square matrix takes the form\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "x_{11}, x_{12} \\\\\n",
    "x_{21}, x_{22} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $x_{21} = x_{12}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main advantage such matrices have over merely square ones is the following: their eigenvectors are *always* perpendicular to each other, and their eigenvalues are *always* all real numbers.\n",
    "\n",
    "> Symmetric matrices are special because a) their eigenvectors are always perpendicular to each other, and their eigenvalues are always real numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We illustrate this fact by running the same visualization as shown previously with a linear function whose matrix is the following symmetric matrix whose values are chosen at random\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "1.45207678, -1.2590952  \\\\\n",
    "-1.2590952 , -1.89481084 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# define a random matrix and visualize its transformation\n",
    "mat2 = mat1 + mat1.T\n",
    "savepath = 'videos/animation_6.mp4'\n",
    "linlib.transform_animators.transform2d_animator(savepath=savepath,mat1 = mat2,num_frames = 100,eigvecs_on = True,fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"1000\" height=\"400\" controls loop>\n",
       "  <source src=\"videos/animation_6.mp4\" type=\"video/mp4\">\n",
       "  </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# load video into notebook\n",
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"1000\" height=\"400\" controls loop>\n",
    "  <source src=\"videos/animation_6.mp4\" type=\"video/mp4\">\n",
    "  </video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvectors here are certainly perpendicular, and this fact holds in general for arbitrary symmetric $N\\times N$ matrix $\\mathbf{X}$.  This fact has significant repercussions in the analysis of such matrices, because given the equation for one eigenvector $\\mathbf{v}$\n",
    "\n",
    "$$\n",
    "\\mathbf{X}\\mathbf{v} = \\lambda \\mathbf{v}\n",
    "$$\n",
    "\n",
    "we can *diagonalize* a symmetric matrix by concatenating its entire set of eigenvectors into a matrix, and its eigenvalues into a diagonal matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking all of the eigenvectors of $\\mathbf{X}$ columnwise into a matrix $\\mathbf{V}$, and placing the corresponding eigenvalues along the diagonal of a matrix $\\mathbf{D}$, we can write the equation above simultaneously for all eigenvectors as \n",
    "\n",
    "$$\n",
    "\\mathbf{X}\\mathbf{V} = \\mathbf{V} \\mathbf{D}\n",
    "$$\n",
    "\n",
    "and because the eigenvectors are perpendicular $\\mathbf{V}$ is an orthonormal matrix, i.e., $\\mathbf{V}\\mathbf{V}^T = \\mathbf{I}$.  Thus left multiplying both sides by $\\mathbf{V}^T$ we can express $\\mathbf{X}$ completely in terms of its eigenvectors/values as \n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\mathbf{V} \\mathbf{D} \\mathbf{V}^T\n",
    "$$\n",
    "\n",
    "Again this expression is referred to as the *diagonalization* of the matrix $\\mathbf{X}$.  This is often referred to as the *Spectral Theorem of Symmetric Matrices*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "656.3px",
    "left": "0px",
    "right": "1228px",
    "top": "116.267px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
